
# Hand Gesture Volume and Brightness Control

## Project Overview

This project utilizes computer vision and hand gesture recognition to control the volume and brightness of your laptop or desktop computer. Using the `OpenCV` library in combination with `MediaPipe`, the program recognizes hand gestures in real time through a webcam and adjusts the system settings accordingly. The left hand controls the brightness, while the right hand controls the volume.

### Key Features

- **Real-Time Hand Tracking:** Utilizes MediaPipe's hand tracking solution to detect and track hand movements in real time.
- **Brightness Control:** Adjusts the screen brightness based on the distance between the thumb and index finger of the left hand.
- **Volume Control:** Modifies the system volume based on the distance between the thumb and index finger of the right hand.
- **User-Friendly Interface:** Displays the webcam feed with visual indicators for hand landmarks and gesture interactions.

## Dependencies

To run this project, you need to have the following Python libraries installed:

- `opencv-python`
- `numpy`
- `mediapipe`
- `screen-brightness-control`
- `pycaw`

You can install these dependencies using pip:

```bash
pip install opencv-python numpy mediapipe screen-brightness-control pycaw
```

## Code Explanation

### Importing Libraries

```python
import cv2
import numpy as np
import mediapipe as mp
import screen_brightness_control as sbc
from math import hypot
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume
from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL
```
- **cv2:** OpenCV library for computer vision tasks.
- **numpy:** For numerical operations.
- **mediapipe:** Library for hand tracking and gesture recognition.
- **screen_brightness_control:** To manipulate screen brightness.
- **pycaw:** To control the audio volume in Windows.

### Main Function

The `main()` function initializes the audio and video settings:

```python
def main():
    devices = AudioUtilities.GetSpeakers()
    interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
    volume = cast(interface, POINTER(IAudioEndpointVolume))
    volRange = volume.GetVolumeRange()
    minVol, maxVol, _ = volRange
```
- **AudioUtilities:** Retrieves the audio device's settings to control the volume.
- **cv2.VideoCapture(0):** Initializes the webcam for video capture.

### Hand Detection and Gesture Control

```python
mpHands = mp.solutions.hands
hands = mpHands.Hands(
    static_image_mode=False,
    model_complexity=1,
    min_detection_confidence=0.75,
    min_tracking_confidence=0.75,
    max_num_hands=2
)
```
- **Hands Class:** Creates a hand detection model with specified configurations.

The main loop processes frames from the webcam and recognizes hand gestures:
```python
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    frame = cv2.flip(frame, 1)
    frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    processed = hands.process(frameRGB)
```
- **frameRGB:** Converts the frame to RGB for processing.

### Landmark Extraction and Control Logic

The code extracts landmarks from the detected hands and computes the distance between specific fingers (thumb and index) to adjust brightness and volume:

```python
left_landmark_list, right_landmark_list = get_left_right_landmarks(frame, processed, draw, mpHands)
```
- **get_left_right_landmarks():** Identifies the thumb and index finger of both hands to compute distances.

The brightness and volume levels are adjusted based on the distances calculated from the hand gestures:

```python
if left_landmark_list:
    left_distance = get_distance(frame, left_landmark_list)
    b_level = np.interp(left_distance, [50, 220], [0, 100])
    sbc.set_brightness(int(b_level))

if right_landmark_list:
    right_distance = get_distance(frame, right_landmark_list)
    vol = np.interp(right_distance, [50, 220], [minVol, maxVol])
    volume.SetMasterVolumeLevel(vol, None)
```

### Utility Functions

- **get_left_right_landmarks():** Processes detected hand landmarks and categorizes them into left and right hand lists.
- **get_distance():** Computes the Euclidean distance between two points (finger tips) to determine the gesture strength.

### Cleanup

At the end of the program, the camera and all OpenCV windows are released and destroyed:

```python
finally:
    cap.release()
    cv2.destroyAllWindows()
```

## Conclusion

This project showcases the integration of hand gesture recognition and system controls using Python. It can be expanded with additional gestures for more functionalities, such as media playback control or application switching. Contributions and improvements to the codebase are welcome!

